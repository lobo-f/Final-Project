{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Required import for web cam integration with model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobof\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn import visual\n",
    "\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco_0001.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the colours to be added when recognizing the objects\n",
    "def random_colors(N, bright = True):\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying the mask to the objects inside the rectangular model\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the objects in the frame to be mapped by the mask, box and label \n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        if label == 'person':\n",
    "           image = apply_mask(image, mask,(135,206,250))\n",
    "           image = cv2.rectangle(image, (x1, y1), (x2, y2), (135,206,250), 1)\n",
    "           image = cv2.putText(\n",
    "               image, caption, (x1, y1), cv2.FONT_HERSHEY_DUPLEX, 1,(135,206,250), 2\n",
    "           )\n",
    "        elif label == 'car':\n",
    "           image = apply_mask(image, mask, color)\n",
    "           image = cv2.rectangle(image, (x1, y1), (x2, y2), (255,165,0), 1)\n",
    "           image = cv2.putText(\n",
    "               image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX,1, (255,165,0), 2\n",
    "           )\n",
    "        else:\n",
    "           image = apply_mask(image, mask, color)\n",
    "           image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "           image = cv2.putText(\n",
    "               image, caption, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2\n",
    "           )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_number = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                20\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir is C:\\Python34\\Mask_RCNN\n",
      "loading annotations into memory...\n",
      "Done (t=22.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#Importing coco and adding the directory \n",
    "import coco\n",
    "config = coco.CocoConfig()\n",
    "#Enter coco path directory\n",
    "COCO_DIR = ROOT_DIR \n",
    "print(\"Dir is\",COCO_DIR)\n",
    "if config.NAME == \"coco\":\n",
    "    dataset = coco.CocoDataset()\n",
    "    dataset.load_coco(COCO_DIR, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir is C:\\Python34\\Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "#Importing coco and adding the directory \n",
    "import coco\n",
    "config = coco.CocoConfig()\n",
    "#Enter coco path directory\n",
    "COCO_DIR = ROOT_DIR \n",
    "print(\"Dir is\",COCO_DIR)\n",
    "if config.NAME == \"last\":\n",
    "    dataset = coco.CocoDataset()\n",
    "    dataset.load_coco(COCO_DIR, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Count: 81\n",
      "  0. BG                                                \n",
      "  1. person                                            \n",
      "  2. bicycle                                           \n",
      "  3. car                                               \n",
      "  4. motorcycle                                        \n",
      "  5. airplane                                          \n",
      "  6. bus                                               \n",
      "  7. train                                             \n",
      "  8. truck                                             \n",
      "  9. boat                                              \n",
      " 10. traffic light                                     \n",
      " 11. fire hydrant                                      \n",
      " 12. stop sign                                         \n",
      " 13. parking meter                                     \n",
      " 14. bench                                             \n",
      " 15. bird                                              \n",
      " 16. cat                                               \n",
      " 17. dog                                               \n",
      " 18. horse                                             \n",
      " 19. sheep                                             \n",
      " 20. cow                                               \n",
      " 21. elephant                                          \n",
      " 22. bear                                              \n",
      " 23. zebra                                             \n",
      " 24. giraffe                                           \n",
      " 25. backpack                                          \n",
      " 26. umbrella                                          \n",
      " 27. handbag                                           \n",
      " 28. tie                                               \n",
      " 29. suitcase                                          \n",
      " 30. frisbee                                           \n",
      " 31. skis                                              \n",
      " 32. snowboard                                         \n",
      " 33. sports ball                                       \n",
      " 34. kite                                              \n",
      " 35. baseball bat                                      \n",
      " 36. baseball glove                                    \n",
      " 37. skateboard                                        \n",
      " 38. surfboard                                         \n",
      " 39. tennis racket                                     \n",
      " 40. bottle                                            \n",
      " 41. wine glass                                        \n",
      " 42. cup                                               \n",
      " 43. fork                                              \n",
      " 44. knife                                             \n",
      " 45. spoon                                             \n",
      " 46. bowl                                              \n",
      " 47. banana                                            \n",
      " 48. apple                                             \n",
      " 49. sandwich                                          \n",
      " 50. orange                                            \n",
      " 51. broccoli                                          \n",
      " 52. carrot                                            \n",
      " 53. hot dog                                           \n",
      " 54. pizza                                             \n",
      " 55. donut                                             \n",
      " 56. cake                                              \n",
      " 57. chair                                             \n",
      " 58. couch                                             \n",
      " 59. potted plant                                      \n",
      " 60. bed                                               \n",
      " 61. dining table                                      \n",
      " 62. toilet                                            \n",
      " 63. tv                                                \n",
      " 64. laptop                                            \n",
      " 65. mouse                                             \n",
      " 66. remote                                            \n",
      " 67. keyboard                                          \n",
      " 68. cell phone                                        \n",
      " 69. microwave                                         \n",
      " 70. oven                                              \n",
      " 71. toaster                                           \n",
      " 72. sink                                              \n",
      " 73. refrigerator                                      \n",
      " 74. book                                              \n",
      " 75. clock                                             \n",
      " 76. vase                                              \n",
      " 77. scissors                                          \n",
      " 78. teddy bear                                        \n",
      " 79. hair drier                                        \n",
      " 80. toothbrush                                        \n"
     ]
    }
   ],
   "source": [
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "#Print count of images, classes and class names \n",
    "#print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "#for i, info in enumerate(dataset.class_info):\n",
    " #   print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "class_names = dataset.class_names\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "     print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import random\n",
    "import itertools\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quit Display\n"
     ]
    }
   ],
   "source": [
    "#Integrating the model with the webcam \n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#out = cv2.VideoWriter('output_catpure.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "\n",
    "#Defining the frame for the model to detect\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    results = model.detect([frame], verbose=0)\n",
    "    \n",
    "    r = results[0]\n",
    "    frame = display_instances(\n",
    "            frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
    "        )\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Quit Display\")\n",
    "        break\n",
    "        \n",
    "#Releases the webcam on pressing q\n",
    "#Prints Quit Display\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In case the camera errors out run this to stop it. \n",
    "#If there is a none type error restart the kernel and clear all outputs\n",
    "#This happens due to resource allocation and array not getting freed\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
